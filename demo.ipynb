{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenZoo Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "from utils import *\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=\"d56f4hd45hd23h4d86h4e5rgstwetgljew\",\n",
    "    base_url=\"http://api.openzoo.ai:8888\" \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'eos',\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'content': '  Why did the unicorn go to the party?\\n'\n",
      "                                     '\\n'\n",
      "                                     'Because it was a \"hoof\"-ton of fun!',\n",
      "                          'function_call': None,\n",
      "                          'role': 'assistant',\n",
      "                          'tool_calls': None}}],\n",
      " 'created': 1712499187,\n",
      " 'id': '870a9dc6c9715bd5-LIS',\n",
      " 'model': 'meta-llama/Llama-2-7b-chat-hf',\n",
      " 'object': 'chat.completion',\n",
      " 'prompt': [],\n",
      " 'system_fingerprint': None,\n",
      " 'usage': {'completion_tokens': 29, 'prompt_tokens': 19, 'total_tokens': 48}}\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"chat\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Tell me a joke about unicorns\"}],\n",
    "    stream=False,\n",
    ")\n",
    "\n",
    "pprint(chat_completion_to_dict(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Streaming inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "Answer: Why did the beaver invite his friends over for dinner? Because he wanted to have a \"wood\" good time!"
     ]
    }
   ],
   "source": [
    "stream = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Tell me a short joke about beavers\"}],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "chunk = None\n",
    "content = \"\"\n",
    "\n",
    "for chunk in stream:\n",
    "    content += chunk.choices[0].text\n",
    "    print(chunk.choices[0].text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '870a9dd08d095bde-LIS',\n",
       " 'created': None,\n",
       " 'model': 'meta-llama/Llama-2-7b-chat-hf',\n",
       " 'object': None,\n",
       " 'system_fingerprint': None,\n",
       " 'usage': {'prompt_tokens': 11, 'completion_tokens': 31, 'total_tokens': 42},\n",
       " 'choices': [{'delta': None,\n",
       "   'finish_reason': 'eos',\n",
       "   'index': None,\n",
       "   'logprobs': None,\n",
       "   'token_id': 2,\n",
       "   'text': '.\\n\\nAnswer: Why did the beaver invite his friends over for dinner? Because he wanted to have a \"wood\" good time!'}]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk.choices[0].text = content\n",
    "chat_completion_chunk_to_dict(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
